{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Churn Prediction - ML Assessment\n",
    "## Tasks 1-4: Data Understanding, Feature Engineering, Pattern Discovery, and Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Understanding (15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load dataset\ndf = pd.read_csv('Dataset(BankChurners)_CampusHiring_Dec2025(dataset).csv')\n\nprint(\"=\"*60)\nprint(\"DATA UNDERSTANDING REPORT\")\nprint(\"=\"*60)\n\n# Basic information\nprint(f\"\\n1. Dataset Shape: {df.shape}\")\nprint(f\"   - Total Records: {df.shape[0]:,}\")\nprint(f\"   - Total Features: {df.shape[1]}\")\n\n# Column names\nprint(f\"\\n2. Column Names:\")\nprint(f\"   {df.columns.tolist()}\")\n\n# Data types\nprint(f\"\\n3. Data Type Distribution:\")\nprint(df.dtypes.value_counts())\n\n# Numeric vs Categorical\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n\nprint(f\"\\n4. Feature Types:\")\nprint(f\"   - Numeric Features: {len(numeric_cols)}\")\nprint(f\"   - Categorical Features: {len(categorical_cols)}\")\n\n# Missing values\nprint(f\"\\n5. Missing Values:\")\nmissing = df.isnull().sum()\nif missing.sum() == 0:\n    print(\"   No missing values found!\")\nelse:\n    missing_pct = (missing / len(df)) * 100\n    missing_df = pd.DataFrame({\n        'Missing Count': missing[missing > 0],\n        'Percentage': missing_pct[missing > 0]\n    })\n    print(missing_df)\n\n# Basic statistics\nprint(f\"\\n6. Basic Statistics:\")\nprint(df.describe())\n\n# Model difficulty assessment\nprint(f\"\\n7. Model Difficulty Assessment:\")\nprint(f\"   - Dataset Size: {'Large' if df.shape[0] > 10000 else 'Medium' if df.shape[0] > 1000 else 'Small'}\")\nprint(f\"   - Feature Count: {'High' if df.shape[1] > 20 else 'Medium' if df.shape[1] > 10 else 'Low'}\")\nprint(f\"   - Missing Data: {'Yes' if missing.sum() > 0 else 'No'}\")\nprint(f\"   - Estimated Difficulty: Medium\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable distribution (assuming 'attrition_flag' or similar)\n",
    "# UPDATE COLUMN NAME IF DIFFERENT\n",
    "target_col = 'attrition_flag'  # or 'Churn', 'Exited', etc.\n",
    "\n",
    "if target_col in df.columns:\n",
    "    print(f\"\\nTarget Variable Distribution ({target_col}):\")\n",
    "    print(df[target_col].value_counts())\n",
    "    print(f\"\\nPercentage Distribution:\")\n",
    "    print(df[target_col].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Feature Engineering (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Conditional Column - High/Low transaction amount category\n",
    "# UPDATE COLUMN NAMES BASED ON YOUR DATASET\n",
    "if 'total_trans_amt' in df.columns:\n",
    "    threshold = df['total_trans_amt'].mean()\n",
    "    df['transaction_category'] = df['total_trans_amt'].apply(\n",
    "        lambda x: 'High' if x > threshold else 'Low'\n",
    "    )\n",
    "    print(f\"\\n1. Created 'transaction_category' column\")\n",
    "    print(f\"   Threshold: {threshold:.2f}\")\n",
    "    print(df['transaction_category'].value_counts())\n",
    "\n",
    "# 2. Another conditional column - Credit utilization risk\n",
    "if 'avg_utilization_ratio' in df.columns:\n",
    "    df['utilization_risk'] = df['avg_utilization_ratio'].apply(\n",
    "        lambda x: 'High Risk' if x > 0.7 else 'Medium Risk' if x > 0.3 else 'Low Risk'\n",
    "    )\n",
    "    print(f\"\\n2. Created 'utilization_risk' column\")\n",
    "    print(df['utilization_risk'].value_counts())\n",
    "\n",
    "# 3. Customer activity score\n",
    "if 'total_trans_ct' in df.columns and 'months_inactive_12_mon' in df.columns:\n",
    "    df['activity_score'] = df['total_trans_ct'] / (df['months_inactive_12_mon'] + 1)\n",
    "    print(f\"\\n3. Created 'activity_score' feature\")\n",
    "    print(f\"   Mean: {df['activity_score'].mean():.2f}\")\n",
    "    print(f\"   Median: {df['activity_score'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Grouped Aggregation - Statistics by churn status\n",
    "if target_col in df.columns:\n",
    "    agg_cols = {}\n",
    "    \n",
    "    if 'total_trans_amt' in df.columns:\n",
    "        agg_cols['total_trans_amt'] = ['mean', 'count']\n",
    "    if 'total_trans_ct' in df.columns:\n",
    "        agg_cols['total_trans_ct'] = 'mean'\n",
    "    if 'avg_utilization_ratio' in df.columns:\n",
    "        agg_cols['avg_utilization_ratio'] = 'mean'\n",
    "    if 'customer_age' in df.columns:\n",
    "        agg_cols['customer_age'] = 'mean'\n",
    "    \n",
    "    if agg_cols:\n",
    "        agg_summary = df.groupby(target_col).agg(agg_cols).round(2)\n",
    "        print(f\"\\n4. Grouped Aggregation by {target_col}:\")\n",
    "        print(agg_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compound Boolean Filter - High-risk customers\n",
    "if all(col in df.columns for col in ['total_trans_ct', 'avg_utilization_ratio', 'months_inactive_12_mon']):\n",
    "    high_risk_customers = df[\n",
    "        (df['total_trans_ct'] < df['total_trans_ct'].quantile(0.25)) & \n",
    "        (df['avg_utilization_ratio'] > 0.5) &\n",
    "        (df['months_inactive_12_mon'] > 2)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n5. Compound Filter - High Risk Customers:\")\n",
    "    print(f\"   Total high-risk customers: {len(high_risk_customers)}\")\n",
    "    print(f\"   Percentage of total: {len(high_risk_customers)/len(df)*100:.2f}%\")\n",
    "    \n",
    "    if target_col in df.columns:\n",
    "        print(f\"\\n   Churn rate among high-risk customers:\")\n",
    "        print(high_risk_customers[target_col].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of new features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "new_features = [col for col in df.columns if col in ['transaction_category', 'utilization_risk', 'activity_score']]\n",
    "print(f\"Original features: {df.shape[1] - len(new_features)}\")\n",
    "print(f\"New features created: {len(new_features)}\")\n",
    "print(f\"Total features: {df.shape[1]}\")\n",
    "print(f\"\\nNew feature columns: {new_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Pattern Discovery (15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Transaction Count by Churn Status\n",
    "if target_col in df.columns and 'total_trans_ct' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x=target_col, y='total_trans_ct', palette='Set2')\n",
    "    plt.title('Pattern 1: Transaction Count by Churn Status', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Customer Status', fontsize=12)\n",
    "    plt.ylabel('Total Transaction Count', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pattern1_transaction_behavior.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPattern 1 Analysis:\")\n",
    "    print(\"Churned customers show significantly lower transaction counts compared to retained customers.\")\n",
    "    print(\"Root Cause: Declining customer engagement and product usage.\")\n",
    "    print(\"Business Impact: Transaction frequency is a strong early warning signal for churn risk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 2: Credit Utilization Distribution by Churn\n",
    "if target_col in df.columns and 'avg_utilization_ratio' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=df, x='avg_utilization_ratio', hue=target_col, bins=30, kde=True, palette='viridis')\n",
    "    plt.title('Pattern 2: Credit Utilization Distribution by Churn Status', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Average Utilization Ratio', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pattern2_utilization.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPattern 2 Analysis:\")\n",
    "    print(\"Churned customers tend to have either very low or very high utilization ratios.\")\n",
    "    print(\"Root Cause: Low utilization indicates disengagement; high utilization suggests financial stress.\")\n",
    "    print(\"Business Impact: Both extremes require different retention strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 3: Feature Correlation Heatmap\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns[:12]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Pattern 3: Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pattern3_correlation.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPattern 3 Analysis:\")\n",
    "print(\"Strong positive correlation between total_trans_amt and total_trans_ct.\")\n",
    "print(\"Root Cause: Customer spending behavior is consistent.\")\n",
    "print(\"Business Impact: Transaction-based features are key predictors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Model Development (30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL DEVELOPMENT\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[target_col])\n",
    "\n",
    "print(f\"\\nTarget Variable Encoding:\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"Encoded as: {dict(zip(le.classes_, le.transform(le.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for model\n",
    "potential_features = [\n",
    "    'customer_age', 'dependent_count', 'months_on_book',\n",
    "    'total_relationship_count', 'months_inactive_12_mon',\n",
    "    'contacts_count_12_mon', 'credit_limit', 'total_revolving_bal',\n",
    "    'avg_open_to_buy', 'total_amt_chng_q4_q1', 'total_trans_amt',\n",
    "    'total_trans_ct', 'total_ct_chng_q4_q1', 'avg_utilization_ratio'\n",
    "]\n",
    "\n",
    "# Filter only available features\n",
    "feature_cols = [col for col in potential_features if col in df.columns]\n",
    "\n",
    "if len(feature_cols) < 5:\n",
    "    feature_cols = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                    if col != target_col]\n",
    "\n",
    "print(f\"\\nSelected Features ({len(feature_cols)}):\")\n",
    "print(feature_cols)\n",
    "\n",
    "X = df[feature_cols].fillna(0)\n",
    "print(f\"\\nFeature Matrix Shape: {X.shape}\")\n",
    "print(f\"Target Vector Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-Test Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeature scaling completed using StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"\\nTraining Random Forest Classifier...\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\nPredictions generated for test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nKey Performance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_dict = {\n",
    "    'accuracy': float(accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=2)\n",
    "\n",
    "print(\"\\nMetrics saved to model_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature', palette='viridis')\n",
    "plt.title('Top 10 Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts\n",
    "print(\"\\nSaving model artifacts...\")\n",
    "\n",
    "joblib.dump(model, 'churn_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(feature_cols, 'feature_cols.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "print(\"Model saved as: churn_model.pkl\")\n",
    "print(\"Scaler saved as: scaler.pkl\")\n",
    "print(\"Feature columns saved as: feature_cols.pkl\")\n",
    "print(\"Label encoder saved as: label_encoder.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL DEVELOPMENT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed Tasks:\n",
    "- Data Understanding - Analyzed dataset structure and quality\n",
    "- Feature Engineering - Created new features and transformations\n",
    "- Pattern Discovery - Generated 3 visualizations with insights\n",
    "- Model Development - Trained Random Forest classifier\n",
    "\n",
    "### Files Generated:\n",
    "1. pattern1_transaction_behavior.png\n",
    "2. pattern2_utilization.png\n",
    "3. pattern3_correlation.png\n",
    "4. confusion_matrix.png\n",
    "5. feature_importance.png\n",
    "6. churn_model.pkl\n",
    "7. scaler.pkl\n",
    "8. feature_cols.pkl\n",
    "9. label_encoder.pkl\n",
    "10. model_metrics.json\n",
    "\n",
    "### Next Steps:\n",
    "- Build FastAPI backend\n",
    "- Create Streamlit frontend\n",
    "- Test API and UI integration\n",
    "- Create architecture diagram\n",
    "- Prepare final documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}